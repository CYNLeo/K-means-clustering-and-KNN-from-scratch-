{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-eZ5cl6LfwY"
      },
      "outputs": [],
      "source": [
        "#  import libraries\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOTpICU-MSZK",
        "outputId": "51ff3944-5628-4272-ea44-875067eea5c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# read dataset\n",
        "if __name__ == '__main__':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    YourFilePath = 'pa1'\n",
        "\n",
        "    train_features = pd.read_csv('/content/drive/MyDrive/'+YourFilePath+'/train_features.csv')\n",
        "    test_features = pd.read_csv('/content/drive/MyDrive/'+YourFilePath+'/test_features.csv')\n",
        "    train_labels = pd.read_csv('/content/drive/MyDrive/'+YourFilePath+'/train_labels.csv')\n",
        "    test_labels = pd.read_csv('/content/drive/MyDrive/'+YourFilePath+'/test_labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYMBXt6-jOgs",
        "outputId": "b2586b29-6ed8-4207-ca90-589152565b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Elevation        Aspect         Slope  \\\n",
            "count  12096.000000  12096.000000  12096.000000   \n",
            "mean    2748.303406    156.311177     16.510499   \n",
            "std      417.822995    109.903370      8.471222   \n",
            "min     1863.000000      0.000000      0.000000   \n",
            "25%     2374.000000     65.000000     10.000000   \n",
            "50%     2751.000000    125.000000     15.000000   \n",
            "75%     3102.000000    259.000000     22.000000   \n",
            "max     3849.000000    360.000000     50.000000   \n",
            "\n",
            "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
            "count                      12096.000000                    12096.000000   \n",
            "mean                         227.905754                       51.165923   \n",
            "std                          210.565445                       61.547238   \n",
            "min                            0.000000                     -146.000000   \n",
            "25%                           67.000000                        5.000000   \n",
            "50%                          180.000000                       32.000000   \n",
            "75%                          330.000000                       79.000000   \n",
            "max                         1343.000000                      554.000000   \n",
            "\n",
            "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
            "count                     12096.000000   12096.000000    12096.000000   \n",
            "mean                       1714.041501     212.864501      218.889550   \n",
            "std                        1329.915391      30.498605       22.787213   \n",
            "min                           0.000000      58.000000       99.000000   \n",
            "25%                         760.000000     196.000000      207.000000   \n",
            "50%                        1308.000000     220.000000      222.000000   \n",
            "75%                        2271.000000     235.000000      235.000000   \n",
            "max                        6836.000000     254.000000      254.000000   \n",
            "\n",
            "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points     Soil_Type  \n",
            "count   12096.000000                        12096.000000  12096.000000  \n",
            "mean      134.802249                         1509.822503     19.148065  \n",
            "std        45.980947                         1096.319966     12.628170  \n",
            "min         0.000000                            0.000000      1.000000  \n",
            "25%       106.000000                          732.000000     10.000000  \n",
            "50%       138.000000                         1256.000000     17.000000  \n",
            "75%       167.000000                         1989.000000     30.000000  \n",
            "max       248.000000                         6993.000000     40.000000  \n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  print(train_features.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOK7u5Ysn2AN"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing\n",
        "def z_score_normalization(input_array):\n",
        "  # input_array: numpy array of shape (num_rows, num_features)\n",
        "  # todo start #\n",
        "  normalized_array = (input_array - np.mean(input_array,axis = 0)) / np.std(input_array,axis = 0)\n",
        "  # todo end #\n",
        "  return normalized_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy1ODj4OiqlX"
      },
      "outputs": [],
      "source": [
        " # Manhattan distance\n",
        "def manhattan_distance(X_train, X_test):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # X_test: numpy array of shape (num_rows_test, num_features)\n",
        "  # todo start #\n",
        "  X_test = np.expand_dims(X_test,1)\n",
        "  distance = np.sum(np.abs(X_train - X_test),axis = 2)\n",
        "  # todo end #\n",
        "  return distance\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train)\n",
        "\n",
        "# Cosine distance\n",
        "def cosine_distance(X_train, X_test):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # X_test: numpy array of shape (num_rows_test, num_features)\n",
        "  # todo start #\n",
        "  numerator = np.sum(np.expand_dims(X_test,axis =1) * X_train,axis = 2)\n",
        "  denominator = np.expand_dims(np.sqrt(np.sum(np.square(X_test),axis = 1)),axis = 1) * (np.sqrt(np.sum(np.square(X_train),axis = 1)))\n",
        "  fraction = numerator / denominator\n",
        "  distance = 1 - fraction\n",
        "  # todo end #\n",
        "  return distance\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification based on the Nearest Neighbors\n",
        "def knn_prediction(distances, y_train, k):\n",
        "  # distance: numpy array of shape (num_rows_test, num_rows_train), return value from previous distance functions\n",
        "  # y_train: numpy array of shape (num_rows_train, ),  the labels of training data\n",
        "  # k: integer, k in \"K-nearest neighbors\"\n",
        "\n",
        "  # todo start #\n",
        "  sort_distance = np.argsort(distances,axis = 1)\n",
        "  y_label = np.take(y_train,sort_distance)[:,:k]\n",
        "  mask = (np.arange(np.max(y_train)+1).reshape(1,1,np.max(y_train)+1) == np.expand_dims(y_label,axis = 2))\n",
        "  count_of_dataPoint = np.sum(mask.astype(int),axis = 1) # total number of each label\n",
        "  prediction = np.argmax(count_of_dataPoint,axis = 1) # Majority voting\n",
        "\n",
        "  #Find tie\n",
        "  tie = (count_of_dataPoint == np.expand_dims(count_of_dataPoint.max(axis = 1),axis = 1))\n",
        "  tie_index = np.where(np.sum(tie,axis = 1) > 1)\n",
        "\n",
        "  #inverse distance\n",
        "  sort_inverse_distance = np.sort(distances,axis = 1)[:,:k]\n",
        "  inverse_distance = 1 / sort_inverse_distance\n",
        "  t = mask * np.expand_dims(inverse_distance,2)\n",
        "  t1 = np.sum(t,axis = 1)\n",
        "  inverse = np.argmax(t1,axis = 1)\n",
        "  prediction[tie_index] = inverse[tie_index]\n",
        "  y_classes = np.arange(np.max(y_train))+1\n",
        "  return prediction,y_classes\n",
        "  # prediction: 1-D numpy array of shape (num_rows_test, )"
      ],
      "metadata": {
        "id": "IsV2GbzdSH7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IBRVc9yGXoe"
      },
      "outputs": [],
      "source": [
        "# Evaluation of the K Nearest Neighbors Classifier\n",
        "def f_score(y_test, prediction, y_classes):\n",
        "  num_classes = np.arange(len(y_classes))+1\n",
        "\n",
        "  # todo start #\n",
        "  f_score_array = np.zeros(len(y_classes))\n",
        "  for i in num_classes:\n",
        "    # Fill in the missing code/s #\n",
        "    TP = np.sum( (prediction == i) & (y_test.flatten() == i))\n",
        "    FP = np.sum( (prediction == i) & (y_test.flatten() != i))\n",
        "    FN = np.sum( (prediction != i) & (y_test.flatten() == i))\n",
        "\n",
        "    precision = TP / (FP+ TP+ np.finfo(float).eps)\n",
        "    recall = TP / (TP + FN)\n",
        "    f1_score = (2 * precision * recall) / (precision + recall )\n",
        "    f_score_array[i-1] = f1_score\n",
        "    # todo end #\n",
        "\n",
        "  return f_score_array\n",
        "  # f_score: 1-D array with shape (num_classes, )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUfhmAJ9ntZV"
      },
      "outputs": [],
      "source": [
        "# Euclidean Distance Calculation\n",
        "def centroid_euclidean_distance(X_train, centroids):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # centroids: numpy array of shape (num_clusters, num_features)\n",
        "  # todo start #\n",
        "  X_train = np.expand_dims(X_train,1)\n",
        "  distance = np.sqrt(np.sum(np.square(X_train - centroids),axis = 2)).T\n",
        "  # todo end #\n",
        "  return distance\n",
        "  # distance: numpy array of shape (num_clusters, num_rows_train)\n",
        "\n",
        "#Cluster Assignment\n",
        "def cluster_assignment(distance):\n",
        "  # distance: numpy array of shape (num_clusters, num_rows_train)\n",
        "  # todo start #\n",
        "  assignments = np.argmin(distance,axis = 0)\n",
        "  #assignments = distance[min,np.arange(distance.shape[1])]\n",
        "  # todo end #\n",
        "  return assignments\n",
        "  # assignment: 1-D numpy array of shape (num_rows_train, )\n",
        "\n",
        "# Calculate New Centroids\n",
        "def calculate_centroids(X_train, assignment, k):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # assignment: 1-D numpy array of shape (num_rows_train, )\n",
        "  # k: a scalar value for the number of clusters (NOTE: Include empty clusters in counting k)\n",
        "\n",
        "  conut = np.bincount(assignment.astype(int)).reshape(k,1)\n",
        "  conut = conut.astype(float)\n",
        "  label = np.arange(k).reshape(k,1)\n",
        "  dup = np.tile(assignment.astype(int),(k,1))\n",
        "  mask = (dup[:,:] == label[:])\n",
        "  mask = mask.astype(float)\n",
        "  new_centroids = (mask @ X_train) / conut\n",
        "\n",
        "  return new_centroids\n",
        "  # new_centroids: numpy array of shape (num_clusters, num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjpvxsAr19Cy"
      },
      "outputs": [],
      "source": [
        "#Stop When There Are No More Cluster Reassignments\n",
        "def k_means_cluster_reassignment(X_train, initial_centroids, max_iterations=100):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # initial_centroids: numpy array of shape (num_clusters, num_features)\n",
        "  # max_terations: the maximum number of iterations for refining the model\n",
        "  centroids = initial_centroids\n",
        "  k = centroids.shape[0]\n",
        "  prev_assignment = None\n",
        "  for iteration in range(max_iterations):\n",
        "    distance = centroid_euclidean_distance(X_train, centroids)\n",
        "    assignment = cluster_assignment(distance)\n",
        "    centroids = calculate_centroids(X_train, assignment, k)\n",
        "    if np.array_equal(assignment, prev_assignment):\n",
        "      break  # Stop if there are no more cluster reassignments\n",
        "\n",
        "    prev_assignment = assignment\n",
        "  return assignment, centroids\n",
        "  # centroids: numpy array of shape (num_clusters, num_features)\n",
        "\n",
        "# Stop When Centroid Change is Below Threshold\n",
        "def k_means_centroid_value(X_train, initial_centroids, max_iterations=100, threshold_value=0.0001):\n",
        "  # X_train: numpy array of shape (num_rows_train, num_features)\n",
        "  # initial_centroids: numpy array of shape (num_clusters, num_features)\n",
        "  # max_terations: the maximum number of iterations for refining the model\n",
        "  # threshold_value: a scaler value for the allowable difference between iterations\n",
        "  centroids = initial_centroids\n",
        "  k = centroids.shape[0]\n",
        "  prev_centroids = None\n",
        "  for iteration in range(max_iterations):\n",
        "    distance = centroid_euclidean_distance(X_train, centroids)\n",
        "    assignment = cluster_assignment(distance)\n",
        "    centroids = calculate_centroids(X_train, assignment, k)\n",
        "    # todo start #\n",
        "    if prev_centroids is not None and np.all(np.abs(centroids - prev_centroids) < threshold_value):\n",
        "      break  # Stop if the centroid values have converged\n",
        "\n",
        "    prev_centroids = centroids\n",
        "  return assignment, centroids\n",
        "  # centroids: numpy array of shape (num_clusters, num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYLtPoWqku1f"
      },
      "outputs": [],
      "source": [
        "# Evaluating the value of k\n",
        "def silhouette_score_for_k(X_train, assignments):\n",
        "  n_samples = len(X_train)\n",
        "  silhouette_scores = []\n",
        "\n",
        "  for i in range(n_samples):\n",
        "      point = X_train[i]\n",
        "      assignment = assignments[i]\n",
        "      same_cluster_distances = np.sqrt(np.sum((X_train[assignments == assignment] - point) ** 2, axis=1))\n",
        "      same_cluster_distances = same_cluster_distances[same_cluster_distances != 0]\n",
        "\n",
        "\n",
        "      other_cluster_distances = []\n",
        "      for j in range(len(X_train)):\n",
        "          if assignments[j] != assignment:\n",
        "              other_cluster_distance = np.mean(np.sqrt(np.sum((X_train[assignments == assignments[j]] - point) ** 2, axis=1)))\n",
        "              other_cluster_distances.append(other_cluster_distance)\n",
        "\n",
        "      if len(other_cluster_distances) == 0:\n",
        "          silhouette_score = 0\n",
        "      else:\n",
        "          min_other_cluster_distance = np.min(other_cluster_distances)\n",
        "          silhouette_score = (min_other_cluster_distance - np.mean(same_cluster_distances)) / max(min_other_cluster_distance, np.mean(same_cluster_distances))\n",
        "\n",
        "      silhouette_scores.append(silhouette_score)\n",
        "      silhouette_coef = np.mean(silhouette_scores)\n",
        "  return silhouette_coef\n",
        "  # silhouette_coef: a scalar value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLIZlI0QQ-Wz",
        "outputId": "c0498945-34fc-43c2-aab7-cae6db7823ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The normalized features of the first 5 samples of X_train are:  [[-3.64531641e-01 -9.58255697e-01 -1.59493603e+00  1.42927013e-01\n",
            "  -8.31362047e-01 -9.05389383e-01  2.66760906e-01  5.75366176e-01\n",
            "   2.87038390e-01  4.35034917e+00  7.80187617e-01]\n",
            " [-3.78892383e-01 -9.12759306e-01 -1.71298762e+00 -7.55414141e-02\n",
            "  -9.28852173e-01 -9.95624417e-01  2.33971167e-01  7.07024400e-01\n",
            "   3.52285503e-01  4.30109144e+00  7.80187617e-01]\n",
            " [ 1.33307398e-01 -1.57519217e-01 -8.86626443e-01  1.90420149e-01\n",
            "   2.24780993e-01  1.10234013e+00  6.93027524e-01  8.38682623e-01\n",
            "   4.30090096e-03  4.20622470e+00 -5.66064681e-01]\n",
            " [-3.66925098e-01 -1.01285137e+00 -1.71298762e+00 -3.55750918e-01\n",
            "  -8.47610401e-01 -9.94872458e-01  2.33971167e-01  6.63138325e-01\n",
            "   3.30536465e-01  4.25274589e+00  7.80187617e-01]\n",
            " [-4.05220409e-01 -2.21214165e-01 -1.24078123e+00  3.42398185e-01\n",
            "  -1.07508736e+00 -1.23850705e+00  5.61868565e-01  7.94796549e-01\n",
            "   1.13046089e-01  4.12412848e+00  7.80187617e-01]]\n",
            "The manhattan distance between the first 5 X_train and first 5 X_test are [[ 9.22482567  9.43327726  7.58189979  9.04521814  9.39654285]\n",
            " [13.57471088 13.40605565 14.85158874 13.08693309 13.23721594]\n",
            " [12.790188   12.60514013 14.34426235 12.71112859 12.75272006]\n",
            " [15.46424038 16.10906578 12.68923149 16.30536023 14.67838281]\n",
            " [11.90509162 12.5786385   8.93992083 12.75099839 11.88652964]]\n",
            "The cosine distance between the first 5 X_train and first 5 X_test are [[0.36141321 0.36115748 0.21135551 0.34743379 0.43599088]\n",
            " [1.00393406 0.97004442 1.08769914 0.97148336 0.91019346]\n",
            " [1.01493531 0.98526882 1.15373734 0.9947695  0.96234311]\n",
            " [1.15816915 1.18215995 1.00670396 1.19932262 1.15119441]\n",
            " [0.60705742 0.64003271 0.3159043  0.64873329 0.69229729]]\n",
            "The predicted classes for the first 10 samples in X_test are  [2 6 7 4 2 1 4 1 6 5]\n",
            "The true classes of these samples are  [2 6 7 4 2 2 4 1 6 5]\n",
            "The F-scores for each class are  [0.63414634 0.57519789 0.68848485 0.87946429 0.84210526 0.72604284\n",
            " 0.90440387]\n",
            "With cluster reassignment as the stopping criteria, the assignments for the first 5 samples of X_train are:  [2 2 2 2 2]\n",
            "With centroid value as the stopping criteria, the assignments for the first 5 samples of X_train are:  [2 2 2 2 2]\n",
            "The silhouette coefficient is  0.10381751140231042\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  X_train = np.array(train_features)\n",
        "  X_test = np.array(test_features)\n",
        "  y_train = np.array(train_labels)\n",
        "  y_test = np.array(test_labels)\n",
        "  np.random.seed(0)\n",
        "  n_clusters=3\n",
        "  initial_centroid = np.random.rand(n_clusters, X_train.shape[1])\n",
        "  n_neighbors=5\n",
        "\n",
        "  # Task 1: Data Preprocessing\n",
        "  X_train = z_score_normalization(X_train)\n",
        "  X_test = z_score_normalization(X_test)\n",
        "  print(\"The normalized features of the first 5 samples of X_train are: \", X_train[:5, :])\n",
        "\n",
        "  # Task 2.1: Manhattan distance\n",
        "  m_distance = manhattan_distance(X_train, X_test)\n",
        "  print('The manhattan distance between the first 5 X_train and first 5 X_test are', m_distance[:5, :5])\n",
        "\n",
        "  # Task 2.2: Cosine distance\n",
        "  c_distance = cosine_distance(X_train, X_test)\n",
        "  print('The cosine distance between the first 5 X_train and first 5 X_test are', c_distance[:5, :5])\n",
        "\n",
        "  # Task 3: Classification based on the Nearest Neighbors\n",
        "  prediction, y_classes = knn_prediction(m_distance, y_train, n_neighbors)\n",
        "  print('The predicted classes for the first 10 samples in X_test are ', prediction[:10])\n",
        "  print('The true classes of these samples are ', y_test[:10].flatten())\n",
        "\n",
        "  # Task 4: Evaluation of the K Nearest Neighbors Classifier\n",
        "  f_score_array = f_score(y_test.flatten(), prediction, y_classes)\n",
        "  print('The F-scores for each class are ', f_score_array)\n",
        "\n",
        "  # Task 5-6: K-Means Clustering\n",
        "  assignment, centroid = k_means_cluster_reassignment(X_train, initial_centroid, max_iterations=100)\n",
        "  print('With cluster reassignment as the stopping criteria, the assignments for the first 5 samples of X_train are: ', assignment[:5])\n",
        "  assignment, centroid = k_means_centroid_value(X_train, initial_centroid, max_iterations=100)\n",
        "  print('With centroid value as the stopping criteria, the assignments for the first 5 samples of X_train are: ', assignment[:5])\n",
        "\n",
        "  # Task 6.3: Evaluating the value of k\n",
        "  silhouette_avg = silhouette_score_for_k(X_train[:300, :], assignment[:300])\n",
        "  print('The silhouette coefficient is ', silhouette_avg)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}